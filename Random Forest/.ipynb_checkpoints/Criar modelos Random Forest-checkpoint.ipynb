{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a494452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "\n",
    "import ta as ta\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "from datetime import datetime\n",
    "\n",
    "from tsmoothie.utils_func import sim_randomwalk\n",
    "from tsmoothie.smoother import *\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import joblib\n",
    "\n",
    "import time\n",
    "\n",
    "def preparar_dados_para_treinamento(anteriores,base_treinamento_normalizada):\n",
    "\n",
    "    previsores = []\n",
    "    preco_real = []\n",
    "\n",
    "    for i in range(anteriores,len(base_treinamento_normalizada)):\n",
    "\n",
    "        previsores.append(base_treinamento_normalizada[i-anteriores:i,0])\n",
    "        preco_real.append(base_treinamento_normalizada[i,0])\n",
    "\n",
    "    previsores,preco_real = np.array(previsores),np.array(preco_real)\n",
    "    previsores = previsores\n",
    "    \n",
    "    return previsores,preco_real\n",
    "\n",
    "def GetTsi(base,gaussian_knots,gaussian_sigma,ewm_span=20):\n",
    "    \n",
    "    tsi_config=[25,13]\n",
    "\n",
    "    resultados_tsi = ta.momentum.TSIIndicator(base[\"Close\"],tsi_config[0],tsi_config[1],False)\n",
    "\n",
    "    tsi_df = pd.DataFrame(resultados_tsi.tsi())\n",
    "    \n",
    "    tsi_df.dropna(inplace=True)\n",
    "    \n",
    "    #Suavizando TSI com médias móveis exponenciais\n",
    "    tsi_df[\"ewm\"] = tsi_df['tsi'].ewm(span = ewm_span).mean()*1.2\n",
    "    #------------------------------------------\n",
    "    \n",
    "    #Suavizanto TSI com gaussian smoother\n",
    "    tsi_np = tsi_df[\"tsi\"].to_numpy()\n",
    "    tsi_np.reshape(1,len(tsi_np))\n",
    "\n",
    "    smoother = GaussianSmoother(n_knots=gaussian_knots, sigma=gaussian_sigma)\n",
    "    smoother.smooth(tsi_np)\n",
    "\n",
    "    tsi_df[\"gaussian\"] = smoother.smooth_data[0]\n",
    "    #------------------------------------------\n",
    "    \n",
    "    return tsi_df\n",
    "\n",
    "def Normalizar(Oscilador,coluna):\n",
    "    \n",
    "    normalizador = MinMaxScaler(feature_range=(0,1))\n",
    "    \n",
    "    if coluna == \"tsi\":\n",
    "        Oscilador_treinamento = Oscilador.iloc[:,0:1].values\n",
    "        \n",
    "    if coluna == \"ewm\":\n",
    "        Oscilador_treinamento = Oscilador.iloc[:,1:2].values\n",
    "        \n",
    "    if coluna == \"gaussian\":\n",
    "        Oscilador_treinamento = Oscilador.iloc[:,2:3].values\n",
    "        \n",
    "    Oscilador_normalizado = normalizador.fit_transform(Oscilador_treinamento)\n",
    "    \n",
    "    return Oscilador_normalizado\n",
    "\n",
    "\n",
    "def Criar_modelo_randomForest(base,anteriores_,filepath,knots_=60,sigma_=0.0003,n_estimators_=100,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1):\n",
    "    \n",
    "    #Extrai o tsi\n",
    "    tsi = GetTsi(base,knots_,sigma_)\n",
    "    #--------------------------------\n",
    "\n",
    "\n",
    "    #Faz a normalização do gaussian do tsi\n",
    "    normalizado = Normalizar(tsi,\"gaussian\")\n",
    "    #--------------------------------\n",
    "\n",
    "\n",
    "    X_train, y_train = preparar_dados_para_treinamento(anteriores_,normalizado)\n",
    "\n",
    "    forest_model = RandomForestRegressor(\n",
    "        random_state=1,\n",
    "        n_estimators=n_estimators_,\n",
    "        max_depth=max_depth_,\n",
    "        min_samples_split=min_samples_split_,\n",
    "        min_samples_leaf=min_samples_leaf_)\n",
    "    \n",
    "    \n",
    "    forest_model.fit(X_train, y_train)\n",
    "    \n",
    "    #joblib.dump(forest_model, \"RandomForest_4.joblib\")\n",
    "    joblib.dump(forest_model, filepath)\n",
    "    \n",
    "    print(\"Modelo \",filepath, \"criado\")\n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_1(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,180,filepath_,knots_=60,sigma_=0.0003,\n",
    "        n_estimators_=200,max_depth_=100,min_samples_split_=4,min_samples_leaf_=5)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_2(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,90,filepath_,knots_=60,sigma_=0.0003,\n",
    "        n_estimators_=300,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_3(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,180,filepath_,knots_=60,sigma_=0.0003,\n",
    "        n_estimators_=200,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_4(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,180,filepath_,knots_=60,sigma_=0.0003,\n",
    "        n_estimators_=400,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_5(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,90,filepath_,knots_=60,sigma_=0.0003,\n",
    "        n_estimators_=400,max_depth_=None,min_samples_split_=4,min_samples_leaf_=5)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_7(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,300,filepath_,knots_=60,sigma_=0.0003,\n",
    "        n_estimators_=100,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_8(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,300,filepath_,knots_=60,sigma_=0.0003,\n",
    "        n_estimators_=500,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_9(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,500,filepath_,knots_=60,sigma_=0.0003,\n",
    "        n_estimators_=300,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_10(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,500,filepath_,knots_=60,sigma_=0.0003,\n",
    "        n_estimators_=500,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "def Criar_modelo_rf_11(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,180,filepath_,knots_=90,sigma_=0.0003,\n",
    "        n_estimators_=200,max_depth_=100,min_samples_split_=4,min_samples_leaf_=5)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_12(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,90,filepath_,knots_=90,sigma_=0.0003,\n",
    "        n_estimators_=300,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_13(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,180,filepath_,knots_=90,sigma_=0.0003,\n",
    "        n_estimators_=200,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_14(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,180,filepath_,knots_=90,sigma_=0.0003,\n",
    "        n_estimators_=400,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_15(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,90,filepath_,knots_=90,sigma_=0.0003,\n",
    "        n_estimators_=400,max_depth_=None,min_samples_split_=4,min_samples_leaf_=5)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_16(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,300,filepath_,knots_=90,sigma_=0.0003,\n",
    "        n_estimators_=100,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_17(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,300,filepath_,knots_=90,sigma_=0.0003,\n",
    "        n_estimators_=500,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_18(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,500,filepath_,knots_=90,sigma_=0.0003,\n",
    "        n_estimators_=300,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n",
    "def Criar_modelo_rf_19(base,filepath_):\n",
    "    \n",
    "    forest_model = Criar_modelo_randomForest(base,500,filepath_,knots_=90,sigma_=0.0003,\n",
    "        n_estimators_=500,max_depth_=None,min_samples_split_=2,min_samples_leaf_=1)\n",
    "    \n",
    "    \n",
    "    return forest_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker =\"PETR3.SA\"\n",
    "\n",
    "df = yf.download(ticker)\n",
    "\n",
    "base = df[\"2018\":]\n",
    "\n",
    "\n",
    "#Atributos\n",
    "anteriores = 500\n",
    "knots = 60\n",
    "sigma = 0.0003\n",
    "n_estimators_ = 500\n",
    "max_depth_ = None\n",
    "min_samples_split_ = 2\n",
    "min_samples_leaf_ = 1\n",
    "filepath_ = \"PETR3_RF_10.joblib\"\n",
    "\n",
    "\n",
    "#TREINAR O MODELO\n",
    "forest_model = Criar_modelo_randomForest(\n",
    "    base,\n",
    "    anteriores,\n",
    "    filepath_,\n",
    "    knots,\n",
    "    sigma,\n",
    "    n_estimators_,\n",
    "    max_depth_,\n",
    "    min_samples_split_,\n",
    "    min_samples_leaf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d775a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "ticker =\"ABEV3.SA\"\n",
    "df = yf.download(ticker)\n",
    "base = df[\"2018\":]\n",
    "\n",
    "\n",
    "ticker_split = ticker.split(\".\")\n",
    "\n",
    "caminho = \"Modelos_\"+ticker_split[0]+\"/\"\n",
    "\n",
    "#CRIAR MODELOS\n",
    "\n",
    "#Modelos com o gaussiano menos sensíveis\n",
    "modelo_rf_1 = Criar_modelo_rf_1(base,caminho+ticker_split[0]+\"_RF_1.joblib\")\n",
    "modelo_rf_2 = Criar_modelo_rf_2(base,caminho+ticker_split[0]+\"_RF_2.joblib\")\n",
    "modelo_rf_3 = Criar_modelo_rf_3(base,caminho+ticker_split[0]+\"_RF_3.joblib\")\n",
    "modelo_rf_4 = Criar_modelo_rf_4(base,caminho+ticker_split[0]+\"_RF_4.joblib\")\n",
    "modelo_rf_5 = Criar_modelo_rf_5(base,caminho+ticker_split[0]+\"_RF_5.joblib\")\n",
    "modelo_rf_7 = Criar_modelo_rf_7(base,caminho+ticker_split[0]+\"_RF_7.joblib\")\n",
    "modelo_rf_8 = Criar_modelo_rf_8(base,caminho+ticker_split[0]+\"_RF_8.joblib\")\n",
    "modelo_rf_9 = Criar_modelo_rf_9(base,caminho+ticker_split[0]+\"_RF_9.joblib\")\n",
    "modelo_rf_10 = Criar_modelo_rf_10(base,caminho+ticker_split[0]+\"_RF_10.joblib\")\n",
    "\n",
    "#Modelos com o gaussiano mais sensíveis\n",
    "modelo_rf_11 = Criar_modelo_rf_11(base,caminho+ticker_split[0]+\"_RF_11.joblib\")\n",
    "modelo_rf_12 = Criar_modelo_rf_12(base,caminho+ticker_split[0]+\"_RF_12.joblib\")\n",
    "modelo_rf_13 = Criar_modelo_rf_13(base,caminho+ticker_split[0]+\"_RF_13.joblib\")\n",
    "modelo_rf_14 = Criar_modelo_rf_14(base,caminho+ticker_split[0]+\"_RF_14.joblib\")\n",
    "modelo_rf_15 = Criar_modelo_rf_15(base,caminho+ticker_split[0]+\"_RF_15.joblib\")\n",
    "modelo_rf_16 = Criar_modelo_rf_16(base,caminho+ticker_split[0]+\"_RF_16.joblib\")\n",
    "modelo_rf_17 = Criar_modelo_rf_17(base,caminho+ticker_split[0]+\"_RF_17.joblib\")\n",
    "modelo_rf_18 = Criar_modelo_rf_18(base,caminho+ticker_split[0]+\"_RF_18.joblib\")\n",
    "modelo_rf_19 = Criar_modelo_rf_19(base,caminho+ticker_split[0]+\"_RF_19.joblib\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
