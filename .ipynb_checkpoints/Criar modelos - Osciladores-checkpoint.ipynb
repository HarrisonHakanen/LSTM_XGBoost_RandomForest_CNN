{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a522d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "import ta as ta\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense,Dropout,LSTM,GRU,RNN,BatchNormalization,GaussianNoise\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "import keras\n",
    "import scipy\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "from tsmoothie.utils_func import sim_randomwalk\n",
    "from tsmoothie.smoother import *\n",
    "\n",
    "import time\n",
    "\n",
    "import ray\n",
    "\n",
    "\n",
    "def preparar_dados_financeiros(ticker,remove_out,start_date=\"\", end_date=\"\"):\n",
    "    base = yf.download(ticker)\n",
    "    \n",
    "    if base[\"Open\"].tail(1)[0] == 0:\n",
    "        base = base[:len(base)-1]\n",
    "    \n",
    "    if (start_date == \"\" or start_date == None) or (end_date == \"\" or end_date == None):\n",
    "        base = base\n",
    "    else:\n",
    "        base = base[start_date:end_date]\n",
    "        \n",
    "    base.dropna(inplace=True)\n",
    "    \n",
    "    if remove_out:\n",
    "        return remover_outliers(base)\n",
    "    else:\n",
    "        return base\n",
    "    \n",
    "def remover_outliers(base):\n",
    "    \n",
    "    z_scores = scipy.stats.zscore(base)\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "    filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "    new_base = base[filtered_entries]\n",
    "    \n",
    "    return new_base\n",
    "\n",
    "\n",
    "def GetCci(base,normalizar=1):\n",
    "    \n",
    "    cci_config=[20,0.015]\n",
    "\n",
    "    resultados_cci = ta.trend.CCIIndicator(base[\"High\"],base[\"Low\"],base[\"Close\"],cci_config[0],cci_config[1],False)\n",
    "\n",
    "    cci_df = pd.DataFrame(resultados_cci.cci())\n",
    "    \n",
    "    cci_df.dropna(inplace=True)\n",
    "    \n",
    "    \n",
    "    if normalizar == 1:\n",
    "        \n",
    "        cci_normalizado = Normalizar(cci_df)\n",
    "        \n",
    "        return cci_normalizado\n",
    "            \n",
    "    return cci_df\n",
    "\n",
    "\n",
    "def GetTsi(base,gaussian_knots,gaussian_sigma,ewm_span=20):\n",
    "    \n",
    "    tsi_config=[25,13]\n",
    "\n",
    "    resultados_tsi = ta.momentum.TSIIndicator(base[\"Close\"],tsi_config[0],tsi_config[1],False)\n",
    "\n",
    "    tsi_df = pd.DataFrame(resultados_tsi.tsi())\n",
    "    \n",
    "    tsi_df.dropna(inplace=True)\n",
    "    \n",
    "    #Suavizando TSI com médias móveis exponenciais\n",
    "    tsi_df[\"ewm\"] = tsi_df['tsi'].ewm(span = ewm_span).mean()*1.2\n",
    "    #------------------------------------------\n",
    "    \n",
    "    #Suavizanto TSI com gaussian smoother\n",
    "    tsi_np = tsi_df[\"tsi\"].to_numpy()\n",
    "    tsi_np.reshape(1,len(tsi_np))\n",
    "\n",
    "    smoother = GaussianSmoother(n_knots=gaussian_knots, sigma=gaussian_sigma)\n",
    "    smoother.smooth(tsi_np)\n",
    "\n",
    "    tsi_df[\"gaussian\"] = smoother.smooth_data[0]\n",
    "    #------------------------------------------\n",
    "    \n",
    "    return tsi_df\n",
    "\n",
    "def GetRoc(base,gaussian_knots,gaussian_sigma,ewm_span=20):\n",
    "    \n",
    "    roc_config=[12]\n",
    "\n",
    "    resultados_roc = ta.momentum.ROCIndicator(df[\"Close\"],roc[0],False)\n",
    "    \n",
    "    roc_df = pd.DataFrame(resultados_roc.roc(),columns=[\"roc\"])\n",
    "    \n",
    "    roc_df.dropna(inplace=True)\n",
    "    \n",
    "    #Suavizanto ROC com gaussian smoother\n",
    "    roc_np = roc_df[\"roc\"].to_numpy()\n",
    "    roc_np.reshape(1,len(roc_np))\n",
    "\n",
    "    smoother = GaussianSmoother(n_knots=gaussian_knots, sigma=gaussian_sigma)\n",
    "    smoother.smooth(roc_np)\n",
    "\n",
    "    roc_df[\"gaussian\"] = smoother.smooth_data[0]\n",
    "    #------------------------------------------\n",
    "    \n",
    "    return roc_df\n",
    "\n",
    "\n",
    "    \n",
    "def GetRsi(base,normalizar=1):\n",
    "    \n",
    "    rsi_config=[14,3,3]\n",
    "\n",
    "    resultados_rsi = ta.momentum.RSIIndicator(base[\"Close\"],rsi_config[0],False)\n",
    "\n",
    "    rsi_df = pd.DataFrame(resultados_rsi.rsi())\n",
    "    \n",
    "    rsi_df.dropna(inplace=True)\n",
    "    \n",
    "    if normalizar == 1:\n",
    "        \n",
    "        rsi_normalizado = Normalizar(rsi_df,0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return rsi_normalizado\n",
    "    \n",
    "    return rsi_df\n",
    "\n",
    "\n",
    "def Normalizar(Oscilador,coluna):\n",
    "    \n",
    "    normalizador = MinMaxScaler(feature_range=(0,1))\n",
    "    \n",
    "    if coluna == \"tsi\":\n",
    "        Oscilador_treinamento = Oscilador.iloc[:,0:1].values\n",
    "        \n",
    "    if coluna == \"ewm\":\n",
    "        Oscilador_treinamento = Oscilador.iloc[:,1:2].values\n",
    "        \n",
    "    if coluna == \"gaussian\":\n",
    "        Oscilador_treinamento = Oscilador.iloc[:,2:3].values\n",
    "        \n",
    "    Oscilador_normalizado = normalizador.fit_transform(Oscilador_treinamento)\n",
    "    \n",
    "    return Oscilador_normalizado\n",
    "\n",
    "def preparar_dados_para_treinamento(anteriores,base_treinamento_normalizada):\n",
    "\n",
    "    previsores = []\n",
    "    preco_real = []\n",
    "\n",
    "    for i in range(anteriores,len(base_treinamento_normalizada)):\n",
    "\n",
    "        previsores.append(base_treinamento_normalizada[i-anteriores:i,0])\n",
    "        preco_real.append(base_treinamento_normalizada[i,0])\n",
    "\n",
    "    previsores,preco_real = np.array(previsores),np.array(preco_real)\n",
    "    previsores = np.reshape(previsores,(previsores.shape[0],previsores.shape[1],1))\n",
    "    \n",
    "    return previsores,preco_real\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def criarRedeNeural(previsores,preco_real,filepath,epocas=300,validacao_cruzada=0,ativacao=\"linear\",otimizador=\"adam\",minimo_delta=1e-15,paciencia_es=10,batch=40):\n",
    "    \n",
    "    regressor = Sequential()\n",
    "    \n",
    "    #1º\n",
    "    regressor.add(LSTM(units=70,return_sequences=True,input_shape=(previsores.shape[1],1)))\n",
    "    regressor.add(Dropout(0.3))\n",
    "\n",
    "    #2º\n",
    "    regressor.add(LSTM(units=70,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "\n",
    "    #3º\n",
    "    regressor.add(LSTM(units=70,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #4º\n",
    "    regressor.add(LSTM(units=70,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #5º\n",
    "    regressor.add(LSTM(units=70,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    '''\n",
    "    #6º\n",
    "    regressor.add(LSTM(units=60,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #7º\n",
    "    regressor.add(LSTM(units=60,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #8º\n",
    "    regressor.add(LSTM(units=60,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #9º\n",
    "    regressor.add(LSTM(units=60,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #10º\n",
    "    regressor.add(LSTM(units=60,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #11º\n",
    "    regressor.add(LSTM(units=60,return_sequences=True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    \n",
    "    #12º\n",
    "    regressor.add(LSTM(units=60,return_sequences=True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    \n",
    "    #13º\n",
    "    regressor.add(LSTM(units=60,return_sequences=True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    \n",
    "    #14º\n",
    "    regressor.add(LSTM(units=80,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #15º\n",
    "    regressor.add(LSTM(units=100,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #16º\n",
    "    regressor.add(LSTM(units=100,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #17º\n",
    "    regressor.add(LSTM(units=100,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #18º\n",
    "    regressor.add(LSTM(units=100,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #19º\n",
    "    regressor.add(LSTM(units=100,return_sequences=True))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    '''\n",
    "    #20º\n",
    "    regressor.add(LSTM(units=70))\n",
    "    regressor.add(Dropout(0.3))\n",
    "    \n",
    "    #21º\n",
    "    regressor.add(Dense(units=1,activation=ativacao))\n",
    "    \n",
    "    \n",
    "    regressor.compile(optimizer=otimizador,loss='mean_squared_error',metrics=['mean_absolute_error'])\n",
    "    \n",
    "    es = EarlyStopping(monitor=\"loss\",min_delta=minimo_delta,patience = paciencia_es,verbose=1)    \n",
    "    rlr = ReduceLROnPlateau(monitor=\"loss\",factor=0.06,patience=5,verbose=1)\n",
    "    mcp = ModelCheckpoint(filepath=filepath,monitor=\"loss\",save_best_only=True,verbose=1)\n",
    "    \n",
    "    \n",
    "    if validacao_cruzada == 1:\n",
    "        \n",
    "        kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "        for train_index, test_index in kf.split(previsores):\n",
    "            X_train, X_test = previsores[train_index], previsores[test_index]\n",
    "            y_train, y_test = preco_real[train_index], preco_real[test_index]\n",
    "\n",
    "            regressor.fit(X_train, y_train, epochs=epocas, batch_size=batch,callbacks=[es,mcp])\n",
    "            score = regressor.evaluate(X_test, y_test, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "            \n",
    "    else:\n",
    "\n",
    "        regressor.fit(previsores,preco_real,epochs=epocas,batch_size=batch,callbacks=[es,mcp])\n",
    "    \n",
    "    return regressor\n",
    "\n",
    "\n",
    "def criarRedeNeural_custom(previsores,preco_real,filepath,qtd_neuronios,qtd_camadas,dropout,epocas=300,validacao_cruzada=0,loss_='mean_squared_error',ativacao=\"linear\",otimizador=\"adam\",minimo_delta=1e-15,paciencia_es=10,batch=40):\n",
    "    \n",
    "    qtd_camadas-=2\n",
    "    \n",
    "    regressor = Sequential()\n",
    "    \n",
    "    i=0\n",
    "    while i < qtd_camadas:\n",
    "        \n",
    "        if i == 0:\n",
    "            regressor.add(LSTM(units=qtd_neuronios,return_sequences=True,input_shape=(previsores.shape[1],1)))\n",
    "            regressor.add(Dropout(dropout))\n",
    "            \n",
    "        else:\n",
    "            regressor.add(LSTM(units=qtd_neuronios,return_sequences=True))\n",
    "            regressor.add(Dropout(dropout))\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "    \n",
    "    regressor.add(LSTM(units=qtd_neuronios))\n",
    "    regressor.add(Dropout(dropout))\n",
    "    \n",
    "    regressor.add(Dense(units=1,activation=ativacao))\n",
    "    \n",
    "    \n",
    "    regressor.compile(optimizer=otimizador,loss=loss_,metrics=['mean_absolute_error'])\n",
    "    \n",
    "    es = EarlyStopping(monitor=\"loss\",min_delta=minimo_delta,patience = paciencia_es,verbose=0)    \n",
    "    rlr = ReduceLROnPlateau(monitor=\"loss\",factor=0.06,patience=5,verbose=0)\n",
    "    mcp = ModelCheckpoint(filepath=filepath,monitor=\"loss\",save_best_only=True,verbose=0)\n",
    "    \n",
    "    if validacao_cruzada == 1:\n",
    "        \n",
    "        kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "        for train_index, test_index in kf.split(previsores):\n",
    "            X_train, X_test = previsores[train_index], previsores[test_index]\n",
    "            y_train, y_test = preco_real[train_index], preco_real[test_index]\n",
    "\n",
    "            regressor.fit(X_train, y_train, epochs=epocas, batch_size=batch,callbacks=[es,mcp],verbose=0)\n",
    "            score = regressor.evaluate(X_test, y_test, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "            \n",
    "    else:\n",
    "\n",
    "        regressor.fit(previsores,preco_real,epochs=epocas,batch_size=batch,callbacks=[es,mcp],verbose=0)\n",
    "    \n",
    "    return regressor\n",
    "\n",
    "@ray.remote\n",
    "def Gaussian_1(base,filepath,k_nots=80,sigma=0.001):\n",
    "    \n",
    "    anteriores = 40\n",
    "    \n",
    "    base = base.tail(1257)\n",
    "    \n",
    "    tsi = GetTsi(base,k_nots,sigma)\n",
    "\n",
    "    normalizado = Normalizar(tsi,\"gaussian\")\n",
    "\n",
    "    previsores,preco_real = preparar_dados_para_treinamento(anteriores,normalizado)\n",
    "\n",
    "    #regressor = criarRedeNeural(previsores,preco_real,\"Modelos_SOMA3\\TSI_Gaussian_4.h5\",epocas=200)\n",
    "\n",
    "    qtd_neuronios = 100\n",
    "    qtd_camadas = 8\n",
    "    dropout = 0.3\n",
    "    epocas = 200\n",
    "    validacao_cruzada = 0\n",
    "    loss_ = 'mean_squared_error'\n",
    "    ativacao = 'linear'\n",
    "    otimizador = 'adam'\n",
    "    minimo_delta = 1e-15\n",
    "    paciencia_es = 10\n",
    "    batch = 32\n",
    "\n",
    "    modelo = criarRedeNeural_custom(previsores,preco_real,filepath,qtd_neuronios,qtd_camadas,dropout,epocas,validacao_cruzada,loss_,ativacao,otimizador,minimo_delta,paciencia_es,batch)\n",
    "    \n",
    "    print(\"Gaussian 1 terminado \",filepath)\n",
    "    \n",
    "    return 1\n",
    "\n",
    "@ray.remote\n",
    "def Gaussian_2(base,filepath,k_nots=80,sigma=0.001):\n",
    "    \n",
    "    anteriores = 15\n",
    "    \n",
    "    base = base.tail(1257)\n",
    "    \n",
    "    tsi = GetTsi(base,k_nots,sigma)\n",
    "\n",
    "    normalizado = Normalizar(tsi,\"gaussian\")\n",
    "\n",
    "    previsores,preco_real = preparar_dados_para_treinamento(anteriores,normalizado)\n",
    "\n",
    "    #regressor = criarRedeNeural(previsores,preco_real,\"Modelos_SOMA3\\TSI_Gaussian_4.h5\",epocas=200)\n",
    "\n",
    "    qtd_neuronios = 60\n",
    "    qtd_camadas = 6\n",
    "    dropout = 0.3\n",
    "    epocas = 200\n",
    "    validacao_cruzada = 0\n",
    "    loss_ = 'mean_squared_error'\n",
    "    ativacao = 'linear'\n",
    "    otimizador = 'adam'\n",
    "    minimo_delta = 1e-15\n",
    "    paciencia_es = 10\n",
    "    batch = 32\n",
    "\n",
    "    modelo = criarRedeNeural_custom(previsores,preco_real,filepath,qtd_neuronios,qtd_camadas,dropout,epocas,validacao_cruzada,loss_,ativacao,otimizador,minimo_delta,paciencia_es,batch)\n",
    "    \n",
    "    print(\"Gaussian 2 terminado \",filepath)\n",
    "    \n",
    "    return 1\n",
    "    \n",
    "@ray.remote\n",
    "def Gaussian_3(base,filepath,k_nots=80,sigma=0.001):\n",
    "    \n",
    "    anteriores = 40\n",
    "    \n",
    "    base = base.tail(1760)\n",
    "    \n",
    "    tsi = GetTsi(base,k_nots,sigma)\n",
    "\n",
    "    normalizado = Normalizar(tsi,\"gaussian\")\n",
    "\n",
    "    previsores,preco_real = preparar_dados_para_treinamento(anteriores,normalizado)\n",
    "\n",
    "    #regressor = criarRedeNeural(previsores,preco_real,\"Modelos_SOMA3\\TSI_Gaussian_4.h5\",epocas=200)\n",
    "\n",
    "    qtd_neuronios = 60\n",
    "    qtd_camadas = 10\n",
    "    dropout = 0.3\n",
    "    epocas = 200\n",
    "    validacao_cruzada = 0\n",
    "    loss_ = 'mean_squared_error'\n",
    "    ativacao = 'linear'\n",
    "    otimizador = 'adam'\n",
    "    minimo_delta = 1e-15\n",
    "    paciencia_es = 10\n",
    "    batch = 40\n",
    "\n",
    "    modelo = criarRedeNeural_custom(previsores,preco_real,filepath,qtd_neuronios,qtd_camadas,dropout,epocas,validacao_cruzada,loss_,ativacao,otimizador,minimo_delta,paciencia_es,batch)\n",
    "    \n",
    "    print(\"Gaussian 3 terminado \",filepath)\n",
    "    \n",
    "    return 1\n",
    "\n",
    "@ray.remote\n",
    "def Gaussian_4(base,filepath,k_nots=80,sigma=0.001):\n",
    "    \n",
    "    anteriores = 15\n",
    "    \n",
    "    base = base.tail(1760)\n",
    "    \n",
    "    tsi = GetTsi(base,k_nots,sigma)\n",
    "\n",
    "    normalizado = Normalizar(tsi,\"gaussian\")\n",
    "\n",
    "    previsores,preco_real = preparar_dados_para_treinamento(anteriores,normalizado)\n",
    "\n",
    "    #regressor = criarRedeNeural(previsores,preco_real,\"Modelos_SOMA3\\TSI_Gaussian_4.h5\",epocas=200)\n",
    "\n",
    "    qtd_neuronios = 60\n",
    "    qtd_camadas = 7\n",
    "    dropout = 0.3\n",
    "    epocas = 200\n",
    "    validacao_cruzada = 0\n",
    "    loss_ = 'mean_squared_error'\n",
    "    ativacao = 'linear'\n",
    "    otimizador = 'adam'\n",
    "    minimo_delta = 1e-15\n",
    "    paciencia_es = 10\n",
    "    batch = 40\n",
    "\n",
    "    modelo = criarRedeNeural_custom(previsores,preco_real,filepath,qtd_neuronios,qtd_camadas,dropout,epocas,validacao_cruzada,loss_,ativacao,otimizador,minimo_delta,paciencia_es,batch)\n",
    "    \n",
    "    print(\"Gaussian 4 terminado \",filepath)\n",
    "    \n",
    "    return 1\n",
    "\n",
    "@ray.remote\n",
    "def Gaussian_5(base,filepath,k_nots=80,sigma=0.001):\n",
    "    \n",
    "    anteriores = 40\n",
    "    \n",
    "    base = base.tail(1760)\n",
    "    \n",
    "    tsi = GetTsi(base,k_nots,sigma)\n",
    "\n",
    "    normalizado = Normalizar(tsi,\"gaussian\")\n",
    "\n",
    "    previsores,preco_real = preparar_dados_para_treinamento(anteriores,normalizado)\n",
    "\n",
    "    #regressor = criarRedeNeural(previsores,preco_real,\"Modelos_SOMA3\\TSI_Gaussian_4.h5\",epocas=200)\n",
    "\n",
    "    qtd_neuronios = 70\n",
    "    qtd_camadas = 10\n",
    "    dropout = 0.3\n",
    "    epocas = 200\n",
    "    validacao_cruzada = 0\n",
    "    loss_ = 'mean_squared_error'\n",
    "    ativacao = 'linear'\n",
    "    otimizador = 'adam'\n",
    "    minimo_delta = 1e-15\n",
    "    paciencia_es = 10\n",
    "    batch = 40\n",
    "\n",
    "    modelo = criarRedeNeural_custom(previsores,preco_real,filepath,qtd_neuronios,qtd_camadas,dropout,epocas,validacao_cruzada,loss_,ativacao,otimizador,minimo_delta,paciencia_es,batch)\n",
    "    \n",
    "    print(\"Gaussian 5 terminado \",filepath)\n",
    "    \n",
    "    return 1\n",
    "\n",
    "@ray.remote\n",
    "def Gaussian_6(base,filepath,k_nots=80,sigma=0.001):\n",
    "    \n",
    "    anteriores = 90\n",
    "    \n",
    "    base = base.tail(1760)\n",
    "    \n",
    "    tsi = GetTsi(base,k_nots,sigma)\n",
    "\n",
    "    normalizado = Normalizar(tsi,\"gaussian\")\n",
    "\n",
    "    previsores,preco_real = preparar_dados_para_treinamento(anteriores,normalizado)\n",
    "\n",
    "    #regressor = criarRedeNeural(previsores,preco_real,\"Modelos_SOMA3\\TSI_Gaussian_4.h5\",epocas=200)\n",
    "\n",
    "    qtd_neuronios = 100\n",
    "    qtd_camadas = 10\n",
    "    dropout = 0.3\n",
    "    epocas = 200\n",
    "    validacao_cruzada = 0\n",
    "    loss_ = 'mean_squared_error'\n",
    "    ativacao = 'linear'\n",
    "    otimizador = 'adam'\n",
    "    minimo_delta = 1e-15\n",
    "    paciencia_es = 10\n",
    "    batch = 32\n",
    "\n",
    "    modelo = criarRedeNeural_custom(previsores,preco_real,filepath,qtd_neuronios,qtd_camadas,dropout,epocas,validacao_cruzada,loss_,ativacao,otimizador,minimo_delta,paciencia_es,batch)\n",
    "    \n",
    "    print(\"Gaussian 6 terminado \",filepath)\n",
    "    \n",
    "    return 1\n",
    "\n",
    "@ray.remote\n",
    "def Gaussian_10(base,filepath,k_nots=80,sigma=0.001):\n",
    "    \n",
    "    anteriores = 15\n",
    "    \n",
    "    base = base.tail(1760)\n",
    "    \n",
    "    tsi = GetTsi(base,k_nots,sigma)\n",
    "\n",
    "    normalizado = Normalizar(tsi,\"gaussian\")\n",
    "\n",
    "    previsores,preco_real = preparar_dados_para_treinamento(anteriores,normalizado)\n",
    "\n",
    "    #regressor = criarRedeNeural(previsores,preco_real,\"Modelos_SOMA3\\TSI_Gaussian_4.h5\",epocas=200)\n",
    "\n",
    "    qtd_neuronios = 80\n",
    "    qtd_camadas = 6\n",
    "    dropout = 0.3\n",
    "    epocas = 200\n",
    "    validacao_cruzada = 0\n",
    "    loss_ = 'mean_squared_error'\n",
    "    ativacao = 'linear'\n",
    "    otimizador = 'adam'\n",
    "    minimo_delta = 1e-15\n",
    "    paciencia_es = 10\n",
    "    batch = 20\n",
    "\n",
    "    modelo = criarRedeNeural_custom(previsores,preco_real,filepath,qtd_neuronios,qtd_camadas,dropout,epocas,validacao_cruzada,loss_,ativacao,otimizador,minimo_delta,paciencia_es,batch)\n",
    "    \n",
    "    print(\"Gaussian 10 terminado \",filepath)\n",
    "    \n",
    "    return 1\n",
    "\n",
    "@ray.remote\n",
    "def Gaussian_11(base,filepath,k_nots=80,sigma=0.001):\n",
    "    \n",
    "    anteriores = 15\n",
    "    \n",
    "    base = base.tail(1760)\n",
    "    \n",
    "    tsi = GetTsi(base,k_nots,sigma)\n",
    "\n",
    "    normalizado = Normalizar(tsi,\"gaussian\")\n",
    "\n",
    "    previsores,preco_real = preparar_dados_para_treinamento(anteriores,normalizado)\n",
    "\n",
    "    #regressor = criarRedeNeural(previsores,preco_real,\"Modelos_SOMA3\\TSI_Gaussian_4.h5\",epocas=200)\n",
    "\n",
    "    qtd_neuronios = 60\n",
    "    qtd_camadas = 12\n",
    "    dropout = 0.3\n",
    "    epocas = 200\n",
    "    validacao_cruzada = 0\n",
    "    loss_ = 'mean_squared_error'\n",
    "    ativacao = 'linear'\n",
    "    otimizador = 'adam'\n",
    "    minimo_delta = 1e-10\n",
    "    paciencia_es = 10\n",
    "    batch = 20\n",
    "\n",
    "    modelo = criarRedeNeural_custom(previsores,preco_real,filepath,qtd_neuronios,qtd_camadas,dropout,epocas,validacao_cruzada,loss_,ativacao,otimizador,minimo_delta,paciencia_es,batch)\n",
    "    \n",
    "    print(\"Gaussian 11 terminado \",filepath)\n",
    "    \n",
    "    return 1\n",
    "\n",
    "\n",
    "def Criar_modelos_gaussian(tickers):\n",
    "    \n",
    "    \n",
    "    ray.init()\n",
    "\n",
    "    rfs = []\n",
    "    retornos = []\n",
    "    i = 0\n",
    "    \n",
    "    for ticker in tickers:\n",
    "\n",
    "        ticker_ = ticker[0].split(\".\")[0]\n",
    "        filepath = \"Modelos_\"+ticker_+\"/\"+ticker_\n",
    "        base = preparar_dados_financeiros(ticker[0],False)\n",
    "\n",
    "        g_k_nots = ticker[1]\n",
    "        g_sigma = ticker[2]\n",
    "\n",
    "        print(\"Começando treinamento do ativo \"+ticker_)\n",
    "    \n",
    "        rfs.append(Gaussian_1.remote(base,filepath+\"_Gaussian_1.h5\",g_k_nots,g_sigma))\n",
    "        rfs.append(Gaussian_2.remote(base,filepath+\"_Gaussian_2.h5\",g_k_nots,g_sigma))\n",
    "        rfs.append(Gaussian_3.remote(base,filepath+\"_Gaussian_3.h5\",g_k_nots,g_sigma))\n",
    "        rfs.append(Gaussian_4.remote(base,filepath+\"_Gaussian_4.h5\",g_k_nots,g_sigma))\n",
    "        rfs.append(Gaussian_5.remote(base,filepath+\"_Gaussian_5.h5\",g_k_nots,g_sigma))\n",
    "        rfs.append(Gaussian_6.remote(base,filepath+\"_Gaussian_6.h5\",g_k_nots,g_sigma))\n",
    "        rfs.append(Gaussian_10.remote(base,filepath+\"_Gaussian_10.h5\",g_k_nots,g_sigma))\n",
    "        rfs.append(Gaussian_11.remote(base,filepath+\"_Gaussian_11.h5\",g_k_nots,g_sigma))\n",
    "        retornos = ray.get(rfs)\n",
    "        \n",
    "        rfs= []\n",
    "    \n",
    "        i+=1    \n",
    "\n",
    "    ray.shutdown()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4c7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc048aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6a3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"PETR3.SA\"\n",
    "\n",
    "anteriores = 12\n",
    "\n",
    "base = preparar_dados_financeiros(ticker,False\"2016\",\"2021\",)\n",
    "\n",
    "tsi = GetTsi(base,80,0.007)\n",
    "\n",
    "normalizado = Normalizar(tsi,\"gaussian\")\n",
    "\n",
    "previsores,preco_real = preparar_dados_para_treinamento(anteriores,normalizado)\n",
    "\n",
    "filepath = \"Modelos_PETR3\\Teste_Gaussian_10.h5\"\n",
    "qtd_neuronios = 80\n",
    "qtd_camadas = 6\n",
    "dropout = 0.3\n",
    "epocas = 200\n",
    "validacao_cruzada = 0\n",
    "loss_ = 'mean_squared_error'\n",
    "ativacao = 'linear'\n",
    "otimizador = 'adam'\n",
    "minimo_delta = 1e-15\n",
    "paciencia_es = 10\n",
    "batch = 20\n",
    "\n",
    "regressor = criarRedeNeural_custom(previsores,\n",
    "                                   preco_real,\n",
    "                                   filepath,\n",
    "                                   qtd_neuronios,\n",
    "                                   qtd_camadas,\n",
    "                                   dropout,epocas,\n",
    "                                   validacao_cruzada,\n",
    "                                   loss_,ativacao,\n",
    "                                   otimizador,\n",
    "                                   minimo_delta,\n",
    "                                   paciencia_es,\n",
    "                                   batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c8e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = time.time()\n",
    "\n",
    "\n",
    "ticker = \"PETR3.SA\"\n",
    "\n",
    "base = preparar_dados_financeiros(ticker,False)\n",
    "\n",
    "\n",
    "Gaussian_1(base,\"Modelos_TOTS3\\TOTS3_Gaussian_1.h5\",k_nots=80,sigma=0.002)\n",
    "Gaussian_2(base,\"Modelos_TOTS3\\TOTS3_Gaussian_2.h5\",k_nots=80,sigma=0.002)\n",
    "Gaussian_3(base,\"Modelos_TOTS3\\TOTS3_Gaussian_3.h5\",k_nots=80,sigma=0.002)\n",
    "Gaussian_4(base,\"Modelos_TOTS3\\TOTS3_Gaussian_4.h5\",k_nots=80,sigma=0.002)\n",
    "Gaussian_5(base,\"Modelos_TOTS3\\TOTS3_Gaussian_5.h5\",k_nots=80,sigma=0.002)\n",
    "Gaussian_6(base,\"Modelos_TOTS3\\TOTS3_Gaussian_6.h5\",k_nots=80,sigma=0.002)\n",
    "Gaussian_10(base,\"Modelos_TOTS3\\TOTS3_Gaussian_10.h5\",k_nots=80,sigma=0.002)\n",
    "Gaussian_11(base,\"Modelos_TOTS3\\TOTS3_Gaussian_11.h5\",k_nots=80,sigma=0.002)\n",
    "\n",
    "fim = time.time()\n",
    "\n",
    "\n",
    "print(\"Duração: \",fim - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bdbde36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 17:33:55,157\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Começando treinamento do ativo MDIA3\n"
     ]
    },
    {
     "ename": "RayTaskError(RuntimeError)",
     "evalue": "\u001b[36mray::Gaussian_3()\u001b[39m (pid=12912, ip=127.0.0.1)\n  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 274, in f\n    raise RuntimeError(\nRuntimeError: The remote function failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n\n\u001b[36mray::Gaussian_3()\u001b[39m (pid=12912, ip=127.0.0.1)\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::Gaussian_3()\u001b[39m (pid=12912, ip=127.0.0.1)\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 265, in fetch_and_register_remote_function\n    function = pickle.loads(serialized_function)\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\__init__.py\", line 20, in <module>\n    from keras import distribute\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\__init__.py\", line 18, in <module>\n    from keras.distribute import sidecar_evaluator\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\", line 17, in <module>\n    import tensorflow.compat.v2 as tf\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n    from tensorflow.python.tools import module_util as _module_util\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 36, in <module>\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 77, in <module>\n    raise ImportError(\nImportError: Traceback (most recent call last):\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRayTaskError(RuntimeError)\u001b[0m                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m tickers_7 \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mARZZ3.SA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m80\u001b[39m,\u001b[38;5;241m0.0035\u001b[39m],[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCYRE3.SA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m80\u001b[39m,\u001b[38;5;241m0.0035\u001b[39m],[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPETR3.SA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m80\u001b[39m,\u001b[38;5;241m0.007\u001b[39m]]\n\u001b[0;32m     20\u001b[0m inicio \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 22\u001b[0m \u001b[43mCriar_modelos_gaussian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m fim \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mCriar_modelos_gaussian\u001b[1;34m(tickers)\u001b[0m\n\u001b[0;32m    621\u001b[0m rfs\u001b[38;5;241m.\u001b[39mappend(Gaussian_10\u001b[38;5;241m.\u001b[39mremote(base,filepath\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Gaussian_10.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,g_k_nots,g_sigma))\n\u001b[0;32m    622\u001b[0m rfs\u001b[38;5;241m.\u001b[39mappend(Gaussian_11\u001b[38;5;241m.\u001b[39mremote(base,filepath\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Gaussian_11.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,g_k_nots,g_sigma))\n\u001b[1;32m--> 623\u001b[0m retornos \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m rfs\u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    627\u001b[0m i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m    \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\worker.py:2309\u001b[0m, in \u001b[0;36mget\u001b[1;34m(object_refs, timeout)\u001b[0m\n\u001b[0;32m   2307\u001b[0m     worker\u001b[38;5;241m.\u001b[39mcore_worker\u001b[38;5;241m.\u001b[39mdump_object_store_memory_usage()\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayTaskError):\n\u001b[1;32m-> 2309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mas_instanceof_cause()\n\u001b[0;32m   2310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[1;31mRayTaskError(RuntimeError)\u001b[0m: \u001b[36mray::Gaussian_3()\u001b[39m (pid=12912, ip=127.0.0.1)\n  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 274, in f\n    raise RuntimeError(\nRuntimeError: The remote function failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n\n\u001b[36mray::Gaussian_3()\u001b[39m (pid=12912, ip=127.0.0.1)\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::Gaussian_3()\u001b[39m (pid=12912, ip=127.0.0.1)\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 265, in fetch_and_register_remote_function\n    function = pickle.loads(serialized_function)\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\__init__.py\", line 20, in <module>\n    from keras import distribute\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\__init__.py\", line 18, in <module>\n    from keras.distribute import sidecar_evaluator\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\", line 17, in <module>\n    import tensorflow.compat.v2 as tf\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n    from tensorflow.python.tools import module_util as _module_util\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 36, in <module>\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 77, in <module>\n    raise ImportError(\nImportError: Traceback (most recent call last):\n  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 17:34:06,765\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::Gaussian_2()\u001b[39m (pid=8056, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 274, in f\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The remote function failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "\u001b[36mray::Gaussian_2()\u001b[39m (pid=8056, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::Gaussian_2()\u001b[39m (pid=8056, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 265, in fetch_and_register_remote_function\n",
      "    function = pickle.loads(serialized_function)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\__init__.py\", line 20, in <module>\n",
      "    from keras import distribute\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\__init__.py\", line 18, in <module>\n",
      "    from keras.distribute import sidecar_evaluator\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\", line 17, in <module>\n",
      "    import tensorflow.compat.v2 as tf\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 36, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 77, in <module>\n",
      "    raise ImportError(\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "See https://www.tensorflow.org/install/errors for some common causes and solutions.\n",
      "If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.\n",
      "2023-02-02 17:34:06,772\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::Gaussian_11()\u001b[39m (pid=8056, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 274, in f\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The remote function failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "\u001b[36mray::Gaussian_11()\u001b[39m (pid=8056, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::Gaussian_11()\u001b[39m (pid=8056, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 265, in fetch_and_register_remote_function\n",
      "    function = pickle.loads(serialized_function)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\__init__.py\", line 20, in <module>\n",
      "    from keras import distribute\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\__init__.py\", line 18, in <module>\n",
      "    from keras.distribute import sidecar_evaluator\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\", line 17, in <module>\n",
      "    import tensorflow.compat.v2 as tf\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 36, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 77, in <module>\n",
      "    raise ImportError(\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "See https://www.tensorflow.org/install/errors for some common causes and solutions.\n",
      "If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.\n",
      "2023-02-02 17:34:06,776\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::Gaussian_6()\u001b[39m (pid=10476, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 274, in f\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The remote function failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "\u001b[36mray::Gaussian_6()\u001b[39m (pid=10476, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::Gaussian_6()\u001b[39m (pid=10476, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 265, in fetch_and_register_remote_function\n",
      "    function = pickle.loads(serialized_function)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\__init__.py\", line 20, in <module>\n",
      "    from keras import distribute\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\__init__.py\", line 18, in <module>\n",
      "    from keras.distribute import sidecar_evaluator\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\", line 17, in <module>\n",
      "    import tensorflow.compat.v2 as tf\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 36, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 77, in <module>\n",
      "    raise ImportError(\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "See https://www.tensorflow.org/install/errors for some common causes and solutions.\n",
      "If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 17:34:06,782\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::Gaussian_4()\u001b[39m (pid=7224, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 274, in f\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The remote function failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "\u001b[36mray::Gaussian_4()\u001b[39m (pid=7224, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::Gaussian_4()\u001b[39m (pid=7224, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 265, in fetch_and_register_remote_function\n",
      "    function = pickle.loads(serialized_function)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\__init__.py\", line 20, in <module>\n",
      "    from keras import distribute\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\__init__.py\", line 18, in <module>\n",
      "    from keras.distribute import sidecar_evaluator\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\", line 17, in <module>\n",
      "    import tensorflow.compat.v2 as tf\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 36, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 77, in <module>\n",
      "    raise ImportError(\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "See https://www.tensorflow.org/install/errors for some common causes and solutions.\n",
      "If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.\n",
      "2023-02-02 17:34:06,790\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::Gaussian_10()\u001b[39m (pid=12912, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 274, in f\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The remote function failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "\u001b[36mray::Gaussian_10()\u001b[39m (pid=12912, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::Gaussian_10()\u001b[39m (pid=12912, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 265, in fetch_and_register_remote_function\n",
      "    function = pickle.loads(serialized_function)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\__init__.py\", line 20, in <module>\n",
      "    from keras import distribute\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\__init__.py\", line 18, in <module>\n",
      "    from keras.distribute import sidecar_evaluator\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\", line 17, in <module>\n",
      "    import tensorflow.compat.v2 as tf\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 36, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 77, in <module>\n",
      "    raise ImportError(\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "See https://www.tensorflow.org/install/errors for some common causes and solutions.\n",
      "If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.\n",
      "2023-02-02 17:34:06,799\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::Gaussian_1()\u001b[39m (pid=10476, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 274, in f\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The remote function failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "\u001b[36mray::Gaussian_1()\u001b[39m (pid=10476, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::Gaussian_1()\u001b[39m (pid=10476, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 265, in fetch_and_register_remote_function\n",
      "    function = pickle.loads(serialized_function)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\__init__.py\", line 20, in <module>\n",
      "    from keras import distribute\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\__init__.py\", line 18, in <module>\n",
      "    from keras.distribute import sidecar_evaluator\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\", line 17, in <module>\n",
      "    import tensorflow.compat.v2 as tf\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 36, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 77, in <module>\n",
      "    raise ImportError(\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "See https://www.tensorflow.org/install/errors for some common causes and solutions.\n",
      "If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 17:34:06,807\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::Gaussian_5()\u001b[39m (pid=7224, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 274, in f\n",
      "    raise RuntimeError(\n",
      "RuntimeError: The remote function failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "\u001b[36mray::Gaussian_5()\u001b[39m (pid=7224, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::Gaussian_5()\u001b[39m (pid=7224, ip=127.0.0.1)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 265, in fetch_and_register_remote_function\n",
      "    function = pickle.loads(serialized_function)\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\__init__.py\", line 20, in <module>\n",
      "    from keras import distribute\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\__init__.py\", line 18, in <module>\n",
      "    from keras.distribute import sidecar_evaluator\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\", line 17, in <module>\n",
      "    import tensorflow.compat.v2 as tf\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 36, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 77, in <module>\n",
      "    raise ImportError(\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Facilimpa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: O arquivo de paginação é muito pequeno para que esta operação seja concluída.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "See https://www.tensorflow.org/install/errors for some common causes and solutions.\n",
      "If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "tickers=[[\"MDIA3.SA\",80,0.003],[\"BRFS3.SA\",80,0.0037],[\"KLBN11.SA\",80,0.003],[\"SUZB3.SA\",80,0.004],\n",
    "         [\"B3SA3.SA\",80,0.0045],[\"ITUB4.SA\",80,0.0045],[\"BBDC3.SA\",80,0.0045],[\"ENGI11.SA\",80,0.0045],\n",
    "         [\"TAEE11.SA\",80,0.0045],[\"ELET6.SA\",80,0.003],[\"EGIE3.SA\",80,0.0037],[\"CSAN3.SA\",80,0.0037],\n",
    "         [\"RRRP3.SA\",80,0.0037],[\"TEND3.SA\",80,0.0037],[\"MOVI3.SA\",80,0.0045],[\"INTB3.SA\",80,0.0045],\n",
    "         [\"GMAT3.SA\",80,0.0045],[\"VIVA3.SA\",80,0.003],[\"LREN3.SA\",80,0.004],[\"SOMA3.SA\",80,0.004],\n",
    "         [\"RAIL3.SA\",80,0.003],[\"IGTI11.SA\",80,0.003],[\"ABEV3.SA\",80,0.004],[\"CRFB3.SA\",80,0.0027],\n",
    "         [\"ARZZ3.SA\",80,0.0035],[\"CYRE3.SA\",80,0.0035],[\"PETR3.SA\",80,0.007]]\n",
    "\n",
    "tickers_1 = [[\"MDIA3.SA\",80,0.003],[\"BRFS3.SA\",80,0.0037],[\"KLBN11.SA\",80,0.003],[\"SUZB3.SA\",80,0.004]]\n",
    "tickers_2 = [[\"B3SA3.SA\",80,0.0045],[\"ITUB4.SA\",80,0.0045],[\"BBDC3.SA\",80,0.0045],[\"ENGI11.SA\",80,0.0045]]\n",
    "tickers_3 = [[\"TAEE11.SA\",80,0.0045],[\"ELET6.SA\",80,0.003],[\"EGIE3.SA\",80,0.0037],[\"CSAN3.SA\",80,0.0037]]\n",
    "tickers_4 = [[\"RRRP3.SA\",80,0.0037],[\"TEND3.SA\",80,0.0037],[\"MOVI3.SA\",80,0.0045],[\"INTB3.SA\",80,0.0045]]\n",
    "tickers_5 = [[\"GMAT3.SA\",80,0.0045],[\"VIVA3.SA\",80,0.003],[\"LREN3.SA\",80,0.004],[\"SOMA3.SA\",80,0.004]]\n",
    "tickers_6 = [[\"RAIL3.SA\",80,0.003],[\"IGTI11.SA\",80,0.003],[\"ABEV3.SA\",80,0.004],[\"CRFB3.SA\",80,0.0027]]\n",
    "tickers_7 = [[\"ARZZ3.SA\",80,0.0035],[\"CYRE3.SA\",80,0.0035],[\"PETR3.SA\",80,0.007]]\n",
    "\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "Criar_modelos_gaussian(tickers_1)\n",
    "\n",
    "fim = time.time()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(fim-inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118ab22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6debfece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
